# -*- coding: utf-8 -*-
"""RAG_YouTube_Tutorial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1StPtrSmFTVq4vZl9uZfH3iPAcAWto6OI
"""

!pip install langchain_community langchainhub chromadb langchain langchain-openai

from google.colab import userdata
import os
os.environ['OPENAI_API_KEY'] = userdata.get('pdf_key')

!pip install pymupdf

from langchain_community.document_loaders import PyMuPDFLoader

# Replace this path with your PDF file path
loader = PyMuPDFLoader("//content//NishitaChaudharyResume.pdf")

docs = loader.load()
print(docs)

!pip install langchain_text_splitter

from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)
splits = text_splitter.split_documents(docs)

print(splits[0])
print(splits[1])
print(splits[2])

print(len(splits))

!pip install langchain_chroma

from langchain_openai import OpenAIEmbeddings

from langchain_chroma import Chroma

vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

print(vectorstore._collection.count())

print(vectorstore._collection.get())

print("\nCollection 1 - ", vectorstore._collection.get(ids=['28651d9a-ab51-41f8-ab83-e68285623c4e'], include=["embeddings", "documents"]))
print("\nCollection 2 - ", vectorstore._collection.get(ids=['054dee19-19ed-4574-bc51-511060fd707a'], include=["embeddings", "documents"]))
print("\nCollection 3 - ", vectorstore._collection.get(ids=['2fd71cb4-835a-43c5-b920-b7e1be51c450'], include=["embeddings", "documents"]))

retriever = vectorstore.as_retriever()

from langchain import hub
prompt = hub.pull("rlm/rag-prompt")

from langchain_openai import ChatOpenAI
llm = ChatOpenAI()

from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

def format_docs(docs):
  return "\n".join(doc.page_content for doc in docs)

rag_chain = ({"context" : retriever | format_docs, "question" : RunnablePassthrough()}
             | prompt
             | llm
             | StrOutputParser())

rag_chain.invoke("Are the recordings of the course available? For how long?")

rag_chain.invoke("Are the testimonials for the course available? Name the studenst who have shared testimonials")

rag_chain.invoke("Are the certificates for the course provided?")

rag_chain.invoke("What all projects are covered in the course?")

from langchain_core.runnables import RunnableLambda

def print_prompt(prompt_text):
  print("Prompt - ", prompt_text)
  return prompt_text

rag_chain_with_print = ({"context" : retriever | format_docs, "question" : RunnablePassthrough()}
             | prompt
             | RunnableLambda(print_prompt)
             | llm
             | StrOutputParser())

rag_chain_with_print.invoke("What all projects are covered in the course?")

